{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c67c1206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser # It is used for p=output parsing\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader # text loader \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter # splitting the document reccursively\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d44ed",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18a75e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents from the folder.\n"
     ]
    }
   ],
   "source": [
    "def load_documents(folder_path: str) -> List[Document]: # returns a list of Document object\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path) # It is a loader for PDF files.\n",
    "        elif filename.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path) # It is a loader for docx file. \n",
    "        else:\n",
    "            print(f\"Unsupported file type: {filename}\") # if the file is none of any type, print unsupported file.\n",
    "            continue\n",
    "        documents.extend(loader.load()) # loader.load() function is specified above.\n",
    "    return documents\n",
    "\n",
    "folder_path = \"D:/MLops/DataScienceProject_1/RAG_ChatBot/docs\"\n",
    "documents = load_documents(folder_path)\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af4004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2024-05-12T03:26:02+00:00', 'author': 'Ujjwal Gupta', 'moddate': '2024-05-12T03:26:02+00:00', 'source': 'D:/MLops/DataScienceProject_1/RAG_ChatBot/docs\\\\Ujjwal Gupta CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content=\"CV \\n \\nSubject: Application for Internship Opportunity at The Indian Patent Offive \\n \\nDear Hiring Manager, \\n \\nI am writing to express my keen interest in the internship opportunity within your esteemed \\norganization, as advertised. With a strong foundation in Computer Science and Engineering, coupled \\nwith a deep passion for Artificial Intelligence (AI) and Machine Learning (ML), I am excited about the \\npossibility of contributing to your team and furthering my professional development in this dynamic \\nfield. \\n \\nCurrently pursuing my second year of B.Tech. in Computer Science and Engineering at Maharaja \\nAgrasen Institute of Technology, my academic journey has been fueled by an unwavering fascination \\nwith computers, development, and automation. Through rigorous exploration of various domains \\nsuch as Android development, cybersecurity, and particularly Data Structures and Algorithms (DSA), I \\nhave honed my computational thinking and problem-solving skills, setting a solid groundwork for my \\nfuture endeavors in AI and ML. \\n \\nMy journey into the realm of AI began with a foray into competitive programming, where I \\ncompleted over 200 questions on platforms like LeetCode, culminating in a victory at a competitive \\nprogramming competition hosted by my college. Building upon this success, I delved deeper into AI \\nthrough Coursera's Deep Learning Specialization by Andrew Ng, achieving outstanding grades and \\ngaining comprehensive theoretical and practical knowledge in the field. \\n \\nDriven by a thirst for practical application, I have undertaken several projects spanning image \\nsegmentation, transfer learning, and neural style transfer, among others. These projects not only \\nallowed me to apply theoretical concepts but also provided invaluable hands-on experience, further \\nenriching my skill set. Currently, I am engaged in a project focused on developing a model for the \\nclassification of counterfeit currency notes, demonstrating my commitment to leveraging AI for real-\\nworld problem-solving. \\n \\nMoreover, my proficiency in mathematics, ranging from basic to advanced concepts, empowers me \\nto comprehend the intricate mathematical foundations underlying AI concepts and tackle complex \\nproblems with precision and creativity. Participation in hackathons has further honed my skills in \\nteamwork, leadership, and adaptability under pressure, fostering collaborative problem-solving \\nwithin constrained time frames.\"),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2024-05-12T03:26:02+00:00', 'author': 'Ujjwal Gupta', 'moddate': '2024-05-12T03:26:02+00:00', 'source': 'D:/MLops/DataScienceProject_1/RAG_ChatBot/docs\\\\Ujjwal Gupta CV.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content=\"Looking ahead, my interests lie in the realms of explainable AI, computer vision, reinforcement \\nlearning, and generative AI, where I aspire to leverage AI's transformative potential for societal \\nbenefit. I am committed to continuous learning and innovation, ensuring that transparency, \\ninterpretability, and ethical considerations remain paramount in my work. \\n \\nThis internship opportunity presents an ideal platform for me to apply and expand my knowledge, \\nwhile also contributing meaningfully to your organization's goals. I am confident that my strong \\nacademic background, practical project experience, and unwavering commitment to excellence make \\nme a strong candidate for this position. \\n \\nThank you for considering my application. I look forward to the opportunity to discuss how my skills \\nand experiences align with the needs of your team. \\n \\nWarm regards, \\n \\nUjjwal Gupta\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-05-09T14:09:22+05:30', 'author': 'Ujjwal', 'moddate': '2025-05-09T14:09:22+05:30', 'source': 'D:/MLops/DataScienceProject_1/RAG_ChatBot/docs\\\\Ujjwal Gupta Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Ujjwal Gupta \\nGithub | Linkedin \\n ujjwalgupta1302@gmail.com | Leetcode | GFG | Contact No. :+91-9958370742 \\nEDUCATION  \\nB.Tech Computer Science and Engineering \\nMaharaja Agrasen Institute of Technology, New Delhi, India (2022 - 2026) \\nGPA: 9.1/10 \\nSKILLS  \\nTech Stack: Machine Learning, Deep Learning (AI/ML), Pandas, NumPy, Scikit -Learn, PyTorch, Transformers. \\nLanguages: Python, JAVA, C/C++, HTML, CSS, JAVASCRIPT, SQL \\nTools and Platforms: Git & GitHub, VS Code, Jupyter Notebook, Google Colab, MLflow, DVC, DagsHub, Apache \\nAirflow, Docker, FastAPI, Flask, MongoDB  \\n \\nPROJECTS  \\nPhishing URL Detection with MLOps Automation \\n|Scikit-Learn, MLflow, DagsHub, Apache Airflow, Astronomer, Docker, GridSearchCV, FastAPI, MongoDB, Python| \\nGitHub | DagsHub \\n• Designed a production-grade MLOps pipeline using Apache Airflow (via Astronomer in Docker)  to automate data \\ningestion from MongoDB, validation, drift detection, model retraining, and deployment for detecting phishng URLs \\nentered by users. \\n• Configured daily retraining via scheduled Airflow DAGs, ensuring the model adapts to new phishing patterns . \\n• Integrated GridSearchCV to tune multiple classifiers (Random Forest, AdaBoost, Gradient Boosting, etc.) and saved the \\nbest model using pickle for deployment. \\n• Tracked experiments and models through MLflow and DagsHub, enabling remote version control, reproducibility, and \\nmodel comparisons. \\n• Deployed the latest model using FastAPI, exposing a /predict endpoint that extracts features from URLs and returns \\nphishing classification with the current version of the model it is using. \\n• Engineered robust preprocessing with custom feature extraction, schema validation, KNN-based imputation, and \\nmodular logging and exception handling. \\n \\nScalable MLOps Pipeline for Annual Health Premium Calculator   \\n| Scikit-Learn, MLflow, DVC, Dags Hub, GridSearchCV , Python, Flask, Logging | Github  | DagsHub \\n• Developed a production-grade ML pipeline that automates data ingestion (downloading, unzipping), data validation, data \\ntransformation (EDA), model training, and evaluation to predict annual health premium based on user inputs. \\n• Integrated GridSearchCV for hyperparameter tuning and saved the best model using joblib for real-time predictions. \\n• Created a Flask-based web UI (with HTML) allowing users to upload data, trigger entire model training pipeline (`/train`), and \\nperform live predictions. \\n• Implemented MLflow and DVC using DagsHub for experiment tracking and reproducibility, with logging and exception \\nhandling throughout the pipeline. \\nEnd-to-End Text Summarization Pipeline \\n| Hugging Face, Transformer, T5 model, PyTorch, FastAPI, Logging, Python  | Github \\n• Developed an end-to-end text summarization pipeline using Hugging Face’s t5-small model which was fine-tuned on the \\nSAMSum dataset. It generates concise summaries of user -inputted conversations or text. \\n• Built an automated pipeline for data ingestion (downloading, unzipping), data transformation, model training, model \\nevaluation (ROUGE metrics) and model deployment, all triggered via the ‘/train’ endpoint in a FastAPI interface. \\n• ‘/predict’ endpoint serves real-time summaries and ‘/metrics’ displays ROUGE evaluation metrics to assess performance of the \\nmost recently trained model. \\n• The project is structured for reproducibility and scalability with Git versioning, modular design, custom scaffolding script and \\nintegrated logging. \\nCERTIFICATION  \\nNeural Networks and Deep Learning (Grade 97.50 percent) Certificate Link January 2024 \\nImproving deep neural network (Grade 97.33 percent) Certificate Link  March 2024 \\nConvolutional Neural Networks (Grade 96.50 percent) Certificate Link May 2024')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3390b",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9662a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b90b5",
   "metadata": {},
   "source": [
    "## Document Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd955a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ujjwal\\AppData\\Local\\Temp\\ipykernel_16136\\1108329480.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "d:\\MLops\\DataScienceProject_1\\RAG_ChatBot\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\MLops\\DataScienceProject_1\\RAG_ChatBot\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ujjwal\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "document_embeddings = embedding_function.embed_documents([split.page_content for split in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8adcf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.10116024315357208,\n",
       " -0.00020280103490222245,\n",
       " 0.04198579117655754,\n",
       " -0.06857962161302567,\n",
       " -0.02047364041209221,\n",
       " -0.04980912804603577,\n",
       " 0.029408005997538567,\n",
       " 0.028651801869273186,\n",
       " -0.05072375386953354,\n",
       " -0.03247469663619995,\n",
       " -0.05381416901946068,\n",
       " -0.07052727788686752,\n",
       " 0.08150126039981842,\n",
       " -0.06255161762237549,\n",
       " -0.03781336173415184,\n",
       " 0.10670776665210724,\n",
       " 0.06844929605722427,\n",
       " -0.08297166228294373,\n",
       " -0.01851995848119259,\n",
       " -0.06903177499771118,\n",
       " 0.023464174941182137,\n",
       " 0.003555864095687866,\n",
       " 0.025925319641828537,\n",
       " -0.0833381935954094,\n",
       " -0.09990009665489197,\n",
       " 0.08743153512477875,\n",
       " 0.069369375705719,\n",
       " -0.03300537168979645,\n",
       " 0.003436449682340026,\n",
       " -0.02685597911477089,\n",
       " 0.029566125944256783,\n",
       " 0.04432011395692825,\n",
       " 0.048100147396326065,\n",
       " 0.046200234442949295,\n",
       " 0.049375344067811966,\n",
       " 0.04202382266521454,\n",
       " -0.03465970605611801,\n",
       " -0.003917180933058262,\n",
       " 0.09273724257946014,\n",
       " -0.05046144872903824,\n",
       " -0.009799106977880001,\n",
       " -0.03801983222365379,\n",
       " -0.002897376660257578,\n",
       " -0.04508008435368538,\n",
       " 0.056323062628507614,\n",
       " -0.03846735879778862,\n",
       " -0.01659543067216873,\n",
       " -0.05975646525621414,\n",
       " -0.003304854966700077,\n",
       " 0.006343382876366377,\n",
       " -0.06971855461597443,\n",
       " -0.03972663730382919,\n",
       " -0.016532380133867264,\n",
       " -0.009963165037333965,\n",
       " -0.10063886642456055,\n",
       " -0.03231091424822807,\n",
       " 0.05755162984132767,\n",
       " -0.006126635707914829,\n",
       " 0.024084333330392838,\n",
       " 0.02133285067975521,\n",
       " 0.038380857557058334,\n",
       " -0.02309507317841053,\n",
       " 0.03128621727228165,\n",
       " 0.05057647079229355,\n",
       " 0.03789249807596207,\n",
       " -0.03545159101486206,\n",
       " -0.03620351105928421,\n",
       " 0.03356527164578438,\n",
       " 0.05846080556511879,\n",
       " -0.03329899162054062,\n",
       " 0.012792063876986504,\n",
       " 0.030418740585446358,\n",
       " -0.08318289369344711,\n",
       " 0.06812797486782074,\n",
       " -0.03698166459798813,\n",
       " 0.005180127918720245,\n",
       " 0.033438730984926224,\n",
       " 0.003939603455364704,\n",
       " 0.10762922465801239,\n",
       " -0.08086094260215759,\n",
       " 0.028132567182183266,\n",
       " 0.0034492549020797014,\n",
       " -0.05049816146492958,\n",
       " 0.09748821705579758,\n",
       " -0.07318049669265747,\n",
       " -0.027755247429013252,\n",
       " -0.01623477041721344,\n",
       " -0.011096403002738953,\n",
       " 0.02610674686729908,\n",
       " -0.009305424056947231,\n",
       " 0.0510057732462883,\n",
       " 7.456428284058347e-05,\n",
       " -0.04777925834059715,\n",
       " -0.009098006412386894,\n",
       " 0.06039854511618614,\n",
       " -0.027919495478272438,\n",
       " 0.006910579279065132,\n",
       " -0.07495579123497009,\n",
       " -0.021708685904741287,\n",
       " 0.07669133692979813,\n",
       " -0.050380889326334,\n",
       " -0.013742601498961449,\n",
       " -0.05517994239926338,\n",
       " 0.0033232152927666903,\n",
       " -0.0786997452378273,\n",
       " -0.022952202707529068,\n",
       " 0.020185384899377823,\n",
       " -0.055809758603572845,\n",
       " 0.08885073661804199,\n",
       " 0.0002426903956802562,\n",
       " 0.02611401304602623,\n",
       " 0.0633183941245079,\n",
       " 0.004316085018217564,\n",
       " -0.014508252963423729,\n",
       " -0.027184560894966125,\n",
       " 0.019922789186239243,\n",
       " -0.05372344329953194,\n",
       " 0.10661162436008453,\n",
       " 0.009443774819374084,\n",
       " 0.03931472450494766,\n",
       " -0.042016226798295975,\n",
       " 0.050786372274160385,\n",
       " -0.07226104289293289,\n",
       " -0.035088129341602325,\n",
       " -0.0212696623057127,\n",
       " -0.1440618634223938,\n",
       " -0.06262750923633575,\n",
       " 1.9951779492521922e-33,\n",
       " -0.012663604691624641,\n",
       " 0.03221067041158676,\n",
       " -0.004808422178030014,\n",
       " 0.019451813772320747,\n",
       " 0.022924313321709633,\n",
       " -0.09290508180856705,\n",
       " 0.04097852110862732,\n",
       " 0.024702200666069984,\n",
       " -0.04909532517194748,\n",
       " -0.014286422170698643,\n",
       " -0.03583264350891113,\n",
       " 0.04696807637810707,\n",
       " 0.013072697445750237,\n",
       " 0.007139635272324085,\n",
       " 0.003707883646711707,\n",
       " 0.021716509014368057,\n",
       " 0.02610718086361885,\n",
       " -0.04405197501182556,\n",
       " 0.024359600618481636,\n",
       " -0.06530909240245819,\n",
       " 0.031228549778461456,\n",
       " -0.1159031018614769,\n",
       " 0.020697016268968582,\n",
       " -0.0038550919853150845,\n",
       " 0.01739688776433468,\n",
       " -0.001708410563878715,\n",
       " 0.07808376848697662,\n",
       " -0.04589331895112991,\n",
       " 0.08752923458814621,\n",
       " 0.02774374559521675,\n",
       " 0.0050279819406569,\n",
       " 0.037092920392751694,\n",
       " -0.12039638310670853,\n",
       " -0.02481425181031227,\n",
       " 0.027244342491030693,\n",
       " 0.041452787816524506,\n",
       " -0.05115761235356331,\n",
       " -0.0994364321231842,\n",
       " 0.0017986735329031944,\n",
       " 0.048847246915102005,\n",
       " -0.08093506097793579,\n",
       " 0.06524660438299179,\n",
       " 0.014376656152307987,\n",
       " -0.07574111968278885,\n",
       " -0.01941145397722721,\n",
       " -0.020051030442118645,\n",
       " 0.03789269179105759,\n",
       " -0.007785660680383444,\n",
       " 0.08663956075906754,\n",
       " 0.003370613558217883,\n",
       " -0.07905633002519608,\n",
       " -0.04651637747883797,\n",
       " 0.02855837158858776,\n",
       " -0.08816509693861008,\n",
       " -0.036747291684150696,\n",
       " 0.02811765857040882,\n",
       " -0.03289254754781723,\n",
       " 0.0017777315806597471,\n",
       " 0.0466374047100544,\n",
       " 0.058392483741045,\n",
       " 0.021444356068968773,\n",
       " -0.009162050671875477,\n",
       " -0.08320985734462738,\n",
       " 0.019716262817382812,\n",
       " -0.062820203602314,\n",
       " -0.029922937974333763,\n",
       " 0.06088846176862717,\n",
       " -0.02702290005981922,\n",
       " 0.13879436254501343,\n",
       " 0.001328778569586575,\n",
       " 0.041480276733636856,\n",
       " 0.002526122611016035,\n",
       " 0.01622510701417923,\n",
       " -0.01036609522998333,\n",
       " -0.06562783569097519,\n",
       " 0.04295019432902336,\n",
       " -0.01852359250187874,\n",
       " -0.018733110278844833,\n",
       " -0.03418385237455368,\n",
       " -0.003025937359780073,\n",
       " -0.045769304037094116,\n",
       " 0.06707467883825302,\n",
       " -0.007961143739521503,\n",
       " -0.053751323372125626,\n",
       " 0.04414268955588341,\n",
       " 0.0023004368413239717,\n",
       " 0.02673005871474743,\n",
       " -0.06814233213663101,\n",
       " -0.04268071800470352,\n",
       " 0.06983638554811478,\n",
       " -0.050020165741443634,\n",
       " 0.02091352455317974,\n",
       " -0.022729137912392616,\n",
       " 0.06545040756464005,\n",
       " -0.05406685173511505,\n",
       " -5.4025000373502455e-33,\n",
       " -0.03191379830241203,\n",
       " -0.014852571301162243,\n",
       " -0.02286491170525551,\n",
       " -0.023851722478866577,\n",
       " 0.08891313523054123,\n",
       " 0.021286649629473686,\n",
       " -0.028687328100204468,\n",
       " 0.06165167689323425,\n",
       " -1.0501686119823717e-05,\n",
       " 0.08585649728775024,\n",
       " -0.008371933363378048,\n",
       " 0.027268216013908386,\n",
       " 0.04066549986600876,\n",
       " 0.0056937262415885925,\n",
       " -0.01421575341373682,\n",
       " 0.02898559160530567,\n",
       " -0.0342935286462307,\n",
       " 0.039801452308893204,\n",
       " -0.010580046102404594,\n",
       " -0.0033692303113639355,\n",
       " 0.033933863043785095,\n",
       " 0.16246482729911804,\n",
       " -0.04989439621567726,\n",
       " -0.00923820398747921,\n",
       " 0.026499196887016296,\n",
       " -0.02260476164519787,\n",
       " -0.06983857601881027,\n",
       " 0.06239292770624161,\n",
       " -0.05981582775712013,\n",
       " 0.054479677230119705,\n",
       " 0.0036556257400661707,\n",
       " 6.345553265418857e-05,\n",
       " -0.11721295863389969,\n",
       " 0.08608732372522354,\n",
       " 0.002480859402567148,\n",
       " 0.030683763325214386,\n",
       " 0.07948606461286545,\n",
       " -0.11254479736089706,\n",
       " 0.03342549130320549,\n",
       " 0.04037681221961975,\n",
       " 0.0035183506552129984,\n",
       " 0.024347316473722458,\n",
       " -0.02269321121275425,\n",
       " -0.03856100142002106,\n",
       " 0.039908912032842636,\n",
       " -0.06977326422929764,\n",
       " -0.023201875388622284,\n",
       " 0.08300897479057312,\n",
       " 0.0497928112745285,\n",
       " -0.1305517703294754,\n",
       " -0.0018981603207066655,\n",
       " 0.009945349767804146,\n",
       " 0.013029532507061958,\n",
       " -0.06417078524827957,\n",
       " 0.024480832740664482,\n",
       " 0.025290891528129578,\n",
       " 0.11121920496225357,\n",
       " -0.025393936783075333,\n",
       " 0.01586933620274067,\n",
       " 0.027196848765015602,\n",
       " 0.0041135274805128574,\n",
       " -0.025643983855843544,\n",
       " 0.07158032059669495,\n",
       " 0.01524653285741806,\n",
       " -0.0642075315117836,\n",
       " 0.06036386638879776,\n",
       " 0.08005224168300629,\n",
       " 0.04373522475361824,\n",
       " -0.06438080221414566,\n",
       " -0.07593175768852234,\n",
       " -0.01469703670591116,\n",
       " 0.004770700354129076,\n",
       " -0.015373419970273972,\n",
       " -0.014638792723417282,\n",
       " -0.08713870495557785,\n",
       " -0.039605818688869476,\n",
       " 0.008014320395886898,\n",
       " 0.01841629296541214,\n",
       " -0.03426782786846161,\n",
       " -0.048017024993896484,\n",
       " -0.04084199294447899,\n",
       " 0.01787986420094967,\n",
       " 0.003894501132890582,\n",
       " 0.02348089963197708,\n",
       " 0.01039791852235794,\n",
       " 0.06920645385980606,\n",
       " -0.0023470623418688774,\n",
       " -0.054876212030649185,\n",
       " 0.0032170999329537153,\n",
       " -0.0067579778842628,\n",
       " -0.10813826322555542,\n",
       " 0.0440613254904747,\n",
       " -0.02130080573260784,\n",
       " 0.027865756303071976,\n",
       " -0.0152992969378829,\n",
       " -5.312520201528059e-08,\n",
       " 0.054519325494766235,\n",
       " -0.005459409672766924,\n",
       " 0.020003344863653183,\n",
       " 0.005587432533502579,\n",
       " 0.04765919968485832,\n",
       " -0.010618112981319427,\n",
       " -0.13155153393745422,\n",
       " 0.009798634797334671,\n",
       " 0.0641622468829155,\n",
       " -0.05919167026877403,\n",
       " 0.0012544388882815838,\n",
       " -0.10971058160066605,\n",
       " -0.06312155723571777,\n",
       " 0.02193373069167137,\n",
       " 0.007499578408896923,\n",
       " 0.05898885428905487,\n",
       " -0.00925093051046133,\n",
       " 0.03054489567875862,\n",
       " -0.010995995253324509,\n",
       " -0.06084982678294182,\n",
       " 0.1549711376428604,\n",
       " -0.005636875983327627,\n",
       " 0.026510920375585556,\n",
       " 0.05322590470314026,\n",
       " 0.041318733245134354,\n",
       " -0.06396161019802094,\n",
       " -0.04766058176755905,\n",
       " -0.07598405331373215,\n",
       " -0.0020937935914844275,\n",
       " 0.03438964858651161,\n",
       " -0.09407488256692886,\n",
       " 0.035920511931180954,\n",
       " 0.07580172270536423,\n",
       " -0.06852474808692932,\n",
       " 0.0529683455824852,\n",
       " 0.0011621235171332955,\n",
       " 0.07066600769758224,\n",
       " -0.0709330290555954,\n",
       " 0.04551399126648903,\n",
       " 0.011009164154529572,\n",
       " -0.024610938504338264,\n",
       " -0.01923302374780178,\n",
       " 0.05840229615569115,\n",
       " -0.027453366667032242,\n",
       " 0.04469824954867363,\n",
       " 0.013782438822090626,\n",
       " 0.04312771558761597,\n",
       " -0.067897729575634,\n",
       " 0.03348848596215248,\n",
       " 0.03433845937252045,\n",
       " -0.014910497702658176,\n",
       " -0.03781762346625328,\n",
       " 0.047104500234127045,\n",
       " 0.06332123279571533,\n",
       " 0.061745624989271164,\n",
       " 0.029935652390122414,\n",
       " -0.02582547441124916,\n",
       " -0.04267527535557747,\n",
       " -0.026585783809423447,\n",
       " 0.06073256954550743,\n",
       " 0.12991119921207428,\n",
       " 0.0005215126438997686,\n",
       " -0.05827055126428604,\n",
       " -0.044761866331100464]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7759446",
   "metadata": {},
   "source": [
    "## Putting Embeddings in chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb787ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and persisted to './chroma_db'\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"my_collection\"\n",
    "vector_db = Chroma.from_documents(\n",
    "    collection_name=collection_name,\n",
    "    documents=splits,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "print(\"Vector store created and persisted to './chroma_db'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646557c1",
   "metadata": {},
   "source": [
    "## Context Retriever Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772e0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_context_retriever_chain(vector_db, llm) :\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "    contextualize_q_system_prompt = \"\"\"\n",
    "        Given a chat history and the latest user question\n",
    "        which might reference context in the chat history,\n",
    "        formulate a standalone question which can be understood\n",
    "        without the chat history. Do NOT answer the question,\n",
    "        just reformulate it if needed and otherwise return it as is.\n",
    "    \"\"\"\n",
    "\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "\n",
    "    return history_aware_retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3f00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_rag_chain(llm) :\n",
    "    retriever_chain = _get_context_retriever_chain(vector_db, llm)\n",
    "    qa_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful AI assistant. Use the following context to answer the user's question.\"),\n",
    "        (\"system\", \"Context: {context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever_chain, question_answer_chain)\n",
    "\n",
    "    return rag_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4efd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: When are skills of Ujjwal Gupta ?\n",
      "AI: Based on the provided CV, Ujjwal Gupta has skills in the domains of Android development, cybersecurity, and Data Structures and Algorithms (DSA).\n",
      "\n",
      "Human: What is his Email-id?\n",
      "AI: I am sorry, but the email id of the applicant is not mentioned in the context.\n"
     ]
    }
   ],
   "source": [
    "# Augmented Generation\n",
    "\n",
    "llm_stream_gemini = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "\n",
    "llm_stream = llm_stream_gemini  # Select between OpenAI and Anthropic models for the response\n",
    "\n",
    "rag_chain = ChatGoogleGenerativeAI(\n",
    "        model=\"models/gemini-2.0-flash-latest\",\n",
    "        temperature=0.3,\n",
    "        convert_system_message_to_human=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "chat_history = []\n",
    "question1 = \"When are skills of Ujjwal Gupta ?\"\n",
    "answer1 = rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})['answer']\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=question1),\n",
    "    AIMessage(content=answer1)\n",
    "])\n",
    "\n",
    "print(f\"Human: {question1}\")\n",
    "print(f\"AI: {answer1}\\n\")\n",
    "\n",
    "question2 = \"What is his Email-id?\"\n",
    "answer2 = rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})['answer']\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=question2),\n",
    "    AIMessage(content=answer2)\n",
    "])\n",
    "\n",
    "print(f\"Human: {question2}\")\n",
    "print(f\"AI: {answer2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
